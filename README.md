# M10_Assignment
In this repository we will be creating a web scraper to parse a table from the Charities Bureau Website by using selenuim python library. The script can be found in scripts folder.
By running the python script the table is loaded into as a dataframe and then is uploaded into a data store in AWS S3 bucket as a csv file which you can find it via the following link and aslo in the files folder!
https://m10-assign.s3.amazonaws.com/charities_bureau_scrape_20210410202050.csv

Next we need to have the result from all pages therefore we iterate through the pages and compile all result into one dataframe, the python script can be found in the scripts folder and also the csv file can be found via the following link from AWS S3 bucket and in the files folder.
https://m10-assign.s3.amazonaws.com/charities_bureau_scrape_20210410211334.csv
